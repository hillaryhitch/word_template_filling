{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ea5db0-fc36-4881-a6e1-c1da7f76b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyodbc-5.1.0 llama-index==0.9.45.post1 arize-phoenix==2.2.1 pyvis diskcache-5.6.3 llama-cpp-python-0.2.76 matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a69d245-21bf-4ae6-be44-4a15121a9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc \n",
    "import pandas as pd\n",
    "\n",
    "import os                                                                                                                                                                                                          \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv(Path(\"/Users/hmwangila/Documents/Documents/datascience_projects/2024/crewagents/agents/src/crewai/env\"))\n",
    "pas=os.getenv(\"DB_PASS\")\n",
    "\n",
    "table='Customer Loyalty Program Management Processes and Systems Review'\n",
    "query=\"\"\"\n",
    "SELECT /* +parallel*/ DISTINCT\n",
    "\tUPPER(a.[ProjectCode]) ProjectCode,\n",
    "\ta.[ProjectTitle],\n",
    "\ta.[Category6] AS [ProjectScore],\n",
    "\t[ActiveAuditPlanTitle] AS [AuditPlanTitle],\n",
    "\ta.[Category9] AS [ProjectQuarter],\t\t\n",
    "\tRTRIM(LTRIM(REPLACE(UPPER(c.EntityTitle), 'DIVISION',''))) as Division,\n",
    "\ta.[Category4] AS [ProjectSource],\t\n",
    "\t[CurrentProjectPhaseValue] AS [ProjectPhase],\n",
    "\t[ScheduledStartDate] AS [ProjectScheduledStartDate],\n",
    "\t[ScheduledEndDate] AS [ProjectScheduledEndDate],\n",
    "\td.IssueTitle,\n",
    "    d.Category4 RiskRating,\n",
    "    d.IsReleased IssueReleased,\n",
    "    d.ReleaseDate IssueReleaseDate,\n",
    "\td.IssueState, \t\n",
    "\te.RecommendationTitle,\n",
    "\tg.Text2 as ManagementAction,\n",
    "\te.DueDate,\n",
    "    e.ReviewDueDate,\n",
    "\tRTRIM(LTRIM(REPLACE(UPPER(e.Category2), 'DIVISION',''))) RecommendationDivision,\n",
    "\te.RecommendationState,\n",
    "\te.Category4 TrackingStatus,\n",
    "\te.LastStatusUpdate,\n",
    "\te.LastStatusUpdateUser,\n",
    "\te.LastStatusUpdateDate,\n",
    "    CASE\n",
    "\t\tWHEN CONVERT(DATE,e.DueDate) < CONVERT(DATE,GETDATE()) AND e.RecommendationState != 'Closed' THEN 'Overdue'\n",
    "\t\t-- WHEN e.DueDate IS NULL AND e.RecommendationState != 'Closed' THEN 'Overdue'\n",
    "\t\t-- WHEN e.DueDate IS NULL AND e.RecommendationState IS NULL THEN 'Overdue'\n",
    "\t\tWHEN FORMAT(CONVERT(DATE,e.DueDate),'yyyyMM') = FORMAT(GetDate(),'yyyyMM') AND e.RecommendationState != 'Closed'\n",
    "            -- THEN 'Due End of ' + FORMAT(CONVERT(DATE,GETDATE()), 'MMMM')\n",
    "            THEN 'Due End Month'\n",
    "\t\tWHEN e.RecommendationState = 'Closed' THEN 'Closed'\n",
    "\t\tELSE 'Not Due'\n",
    "\tEND AS OverdueDescription,\n",
    "\tCASE\n",
    "\t\tWHEN CONVERT(DATE,e.DueDate) < CONVERT(DATE,GETDATE()) AND e.RecommendationState != 'Closed' THEN 1\n",
    "\t\t-- WHEN e.DueDate IS NULL AND e.RecommendationState != 'Closed' THEN 1\n",
    "\t\t-- WHEN e.DueDate IS NULL AND e.RecommendationState IS NULL THEN 1\n",
    "\t\tWHEN e.RecommendationState = 'Closed' THEN 0\n",
    "\t\tELSE 0\n",
    "\tEND AS OverdueStatus,\n",
    "\tCASE\n",
    "\t\tWHEN CONVERT(DATE,e.DueDate) < CONVERT(DATE,GETDATE()) AND e.RecommendationState != 'Closed'\n",
    "\t\t\tTHEN DATEDIFF(day,CONVERT(DATE,ISNULL(e.DueDate, GetDate())),CONVERT(DATE,GETDATE()))\t\n",
    "\t\tELSE 0\n",
    "\tEND AS OverdueDays,\n",
    " \n",
    "    -- d.CreatedUserName as Auditor\n",
    "\t-- e.LastNotStartedUser as Auditor\n",
    "    f.AssignedUserName  as Auditor,\n",
    "\tpvt.[IssueOwner],\n",
    "\tpvt.[SeniorManager],\n",
    "\tpvt.HOD\n",
    "    \n",
    "FROM (select * from [TeamMateReporting].[dbo].[V_ReportApi_Project] where lower([ProjectTitle]) like '%Customer Loyalty Program Management Processes and Systems Review%') a\n",
    "\n",
    "inner join [TeamMateReporting].[dbo].[V_ReportApi_ObjectRelationship] b on a.ProjectID = b.ProjectID\n",
    "inner join [TeamMateReporting].[dbo].[V_ReportApi_Entity] c on b.[EntityID] = c.[EntityID]\n",
    "LEFT join [TeamMateReporting].[dbo].[V_ReportApi_Issue] d on b.IssueID = d.IssueId\n",
    "LEFT join [TeamMateReporting].[dbo].[V_ReportApi_Recommendation] e on b.RecommendationID = e.RecommendationId\n",
    "LEFT JOIN [TeamMateReporting].[dbo].[V_ReportApi_RecommendationText] g on e.RecommendationId = g.RecommendationId\n",
    "LEFT JOIN (SELECT * FROM (\n",
    "SELECT SecurityAssignmentId, IssueId, RoleTitle, AssignedUserName,\n",
    "RANK() OVER(PARTITION BY IssueId ORDER BY SecurityAssignmentId DESC) as preparer_rank\n",
    "FROM [TeamMateReporting].[dbo].V_ReportApi_SecurityAssignment\n",
    "WHERE 1=1\n",
    "AND RoleTitle = 'Preparer'\n",
    "and IssueId IS NOT NULL\n",
    ") preps\n",
    "WHERE 1=1\n",
    "AND preparer_rank = 1) f on f.IssueId = d.IssueId\n",
    "left join (\n",
    "SELECT RecommendationId, RecommendationTitle,\n",
    "[Business Contact] as [IssueOwner], [Business Reviewer] as [SeniorManager], [Business Observer] as [HOD]\n",
    "FROM\n",
    "(SELECT A.RecommendationId, A.RecommendationTitle,\n",
    "   CONCAT(C.FirstName, ' ', C.LastName) StaffName,\n",
    "   D.[StringResourceValue]  \n",
    "  \n",
    "  FROM [TeamMateReporting].[dbo].[V_ReportApi_Recommendation] a\n",
    "  LEFT JOIN [TeamMateReporting].[dbo].[FACT_AssigneeRoleAssignment] B ON A.RecommendationId = B.ObjectID\n",
    "  LEFT JOIN [TeamMateReporting].[dbo].[V_ReportApi_User] C ON C.UserID = B.AssigneeObjectID\n",
    "  LEFT JOIN [TeamMateReporting].[dbo].[V_NG_List_SysSecRole] D ON D.ID = B.RoleLID\n",
    "  where 1=1\n",
    "  --and A.RecommendationTitle = 'Customers should be assigned distinct device serial numbers when loans are issued'\n",
    "  AND (a.RecommendationState != 'Closed' or a.RecommendationState is null)\n",
    "  ) AS SourceTable\n",
    "PIVOT\n",
    "(\n",
    "Max(StaffName)\n",
    "FOR [StringResourceValue] IN ([Business Contact], [Business Reviewer],[Business Observer])\n",
    ") AS PivotTable\n",
    ") as pvt on pvt.RecommendationId = e.RecommendationId\n",
    "Where 1=1\n",
    "-- and (a.[CurrentProjectPhaseValue] IN ('Implementation Tracking', 'Migrated Implementation Tracking','Finalised','Migrated Issued','Responses Accepted') or a.[CurrentProjectPhaseValue] is null)\n",
    "-- AND (a.[Category4] != 'Special Assignment' or a.[Category4] is null)\n",
    "-- AND UPPER([ProjectCode]) NOT LIKE '%SP%'\n",
    "-- uncomment below\n",
    "AND d.IsReleased = '1'\n",
    "-- end of uncomment\n",
    "-- AND e.RecommendationTitle IS NOT NULL\n",
    "---AND (e.RecommendationState != 'Closed' or e.RecommendationState is null)\"\"\"\n",
    "\n",
    "\n",
    "# query=\"\"\"select distinct(a.[ProjectTitle]) from [TeamMateReporting].[dbo].[V_ReportApi_Project] a\"\"\"\n",
    "\n",
    "# @tool\n",
    "\n",
    "def number_to_ordinal(n):\n",
    "    # Convert a number to its ordinal representation\n",
    "    if 11 <= (n % 100) <= 13:\n",
    "        suffix = 'th'\n",
    "    else:\n",
    "        suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(n % 10, 'th')\n",
    "    return str(n) + suffix\n",
    "        \n",
    "def query_tool(query: str) -> str:\n",
    "    sentences = []\n",
    "    flattened_list = []\n",
    "    conn = pyodbc.connect(\"DRIVER={ODBC Driver 18 for SQL Server};\"\n",
    "                          \"SERVER=172.29.250.142,1433;\"\n",
    "                          \"DATABASE=TeamMateReporting;\"\n",
    "                          \"UID=bigdata_user;\"\n",
    "                          f\"PWD={pas};\"\n",
    "                          \"Login Timeout=30000;Encrypt=no;\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    columns = [column[0] for column in cursor.description]\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    df = pd.DataFrame.from_records(result, columns=columns)    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49752f2a-6403-4da8-855f-111e7b857914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "from llama_index.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    ")\n",
    "from llama_index.query_engine.pandas import PandasInstructionParser\n",
    "from llama_index.prompts import PromptTemplate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80b88f40-709e-46fe-9d57-0229f1446d94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 23 key-value pairs and 195 tensors from /Users/hmwangila/Downloads/Phi-3-mini-128k-instruct.Q5_K_S.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
      "llama_model_loader: - kv   2:                        phi3.context_length u32              = 131072\n",
      "llama_model_loader: - kv   3:                      phi3.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   4:                   phi3.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   5:                           phi3.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi3.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi3.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi3.rope.dimension_count u32              = 96\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  129 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 323/32064 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi3\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32064\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 96\n",
      "llm_load_print_meta: n_embd_head_k    = 96\n",
      "llm_load_print_meta: n_embd_head_v    = 96\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
      "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 3.82 B\n",
      "llm_load_print_meta: model size       = 2.46 GiB (5.53 BPW) \n",
      "llm_load_print_meta: general.name     = Phi3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =    74.28 MiB, (  942.05 / 10922.67)\n",
      "llm_load_tensors: offloading 1 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 1/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  2518.40 MiB\n",
      "llm_load_tensors:      Metal buffer size =    74.28 MiB\n",
      "....................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3904\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1 Pro\n",
      "ggml_metal_init: picking default device: Apple M1 Pro\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M1 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1418.25 MiB\n",
      "llama_kv_cache_init:      Metal KV buffer size =    45.75 MiB\n",
      "llama_new_context_with_model: KV self size  = 1464.00 MiB, K (f16):  732.00 MiB, V (f16):  732.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      Metal compute buffer size =   287.63 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   287.63 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 3\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'system') %}{{'<|system|>' + '\\n' + message['content'] + '<|end|>' + '\\n'}}{% elif (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif message['role'] == 'assistant' %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '16', 'general.quantization_version': '2', 'phi3.rope.dimension_count': '96', 'tokenizer.ggml.bos_token_id': '1', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.attention.head_count_kv': '32', 'phi3.attention.head_count': '32', 'tokenizer.ggml.model': 'llama', 'phi3.block_count': '32', 'general.architecture': 'phi3', 'phi3.feed_forward_length': '8192', 'phi3.embedding_length': '3072', 'general.name': 'Phi3', 'phi3.context_length': '131072'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'system') %}{{'<|system|>' + '\n",
      "' + message['content'] + '<|end|>' + '\n",
      "'}}{% elif (message['role'] == 'user') %}{{'<|user|>' + '\n",
      "' + message['content'] + '<|end|>' + '\n",
      "' + '<|assistant|>' + '\n",
      "'}}{% elif message['role'] == 'assistant' %}{{message['content'] + '<|end|>' + '\n",
      "'}}{% endif %}{% endfor %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from llama_index.llms.llama_utils import (\n",
    "    messages_to_prompt,\n",
    "    completion_to_prompt,\n",
    ")\n",
    "llm = LlamaCPP(\n",
    "# optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "model_path=\"/Users/hmwangila/Downloads/Phi-3-mini-128k-instruct.Q5_K_S.gguf\",#Meta-Llama-3-8B.Q5_K_M.gguf\",\n",
    "temperature=0.7,\n",
    "max_new_tokens=256,\n",
    "# llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "context_window=3900,\n",
    "# kwargs to pass to __call__()\n",
    "generate_kwargs={},\n",
    "# kwargs to pass to __init__()\n",
    "# set to at least 1 to use GPU\n",
    "model_kwargs={\"n_gpu_layers\": 1},\n",
    "# transform inputs into Llama2 format\n",
    "messages_to_prompt=messages_to_prompt,\n",
    "completion_to_prompt=completion_to_prompt,\n",
    "verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86de6f93-9015-448d-a8f4-97b542718d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectCode</th>\n",
       "      <th>ProjectTitle</th>\n",
       "      <th>ProjectScore</th>\n",
       "      <th>AuditPlanTitle</th>\n",
       "      <th>ProjectQuarter</th>\n",
       "      <th>Division</th>\n",
       "      <th>ProjectSource</th>\n",
       "      <th>ProjectPhase</th>\n",
       "      <th>ProjectScheduledStartDate</th>\n",
       "      <th>ProjectScheduledEndDate</th>\n",
       "      <th>...</th>\n",
       "      <th>LastStatusUpdate</th>\n",
       "      <th>LastStatusUpdateUser</th>\n",
       "      <th>LastStatusUpdateDate</th>\n",
       "      <th>OverdueDescription</th>\n",
       "      <th>OverdueStatus</th>\n",
       "      <th>OverdueDays</th>\n",
       "      <th>Auditor</th>\n",
       "      <th>IssueOwner</th>\n",
       "      <th>SeniorManager</th>\n",
       "      <th>HOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-FY23</td>\n",
       "      <td>Customer Loyalty Program Management Processes...</td>\n",
       "      <td>Requires attention (75%)</td>\n",
       "      <td>FY23 Audit plan</td>\n",
       "      <td>Q1</td>\n",
       "      <td>CONSUMER BUSINESS</td>\n",
       "      <td>Annual Audit Plan</td>\n",
       "      <td>Finalised</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Update from Lilian Nyambu- For the implementat...</td>\n",
       "      <td>Awuor Lourrine Juliet</td>\n",
       "      <td>2023-04-03 12:12:22.630</td>\n",
       "      <td>Closed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Awuor Lourrine Juliet</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-FY23</td>\n",
       "      <td>Customer Loyalty Program Management Processes...</td>\n",
       "      <td>Requires attention (75%)</td>\n",
       "      <td>FY23 Audit plan</td>\n",
       "      <td>Q1</td>\n",
       "      <td>CONSUMER BUSINESS</td>\n",
       "      <td>Annual Audit Plan</td>\n",
       "      <td>Finalised</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>...</td>\n",
       "      <td>The large SME customers with fixed services we...</td>\n",
       "      <td>Mildred Olima</td>\n",
       "      <td>2023-03-27 07:56:57.980</td>\n",
       "      <td>Closed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Awuor Lourrine Juliet</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-FY23</td>\n",
       "      <td>Customer Loyalty Program Management Processes...</td>\n",
       "      <td>Requires attention (75%)</td>\n",
       "      <td>FY23 Audit plan</td>\n",
       "      <td>Q1</td>\n",
       "      <td>CONSUMER BUSINESS</td>\n",
       "      <td>Annual Audit Plan</td>\n",
       "      <td>Finalised</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>...</td>\n",
       "      <td>The customer journey was reviewed and revised ...</td>\n",
       "      <td>Awuor Lourrine Juliet</td>\n",
       "      <td>2023-11-01 14:42:51.113</td>\n",
       "      <td>Closed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mildred Olima</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-FY23</td>\n",
       "      <td>Customer Loyalty Program Management Processes...</td>\n",
       "      <td>Requires attention (75%)</td>\n",
       "      <td>FY23 Audit plan</td>\n",
       "      <td>Q1</td>\n",
       "      <td>CONSUMER BUSINESS</td>\n",
       "      <td>Annual Audit Plan</td>\n",
       "      <td>Finalised</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>...</td>\n",
       "      <td>The churned customer accounts have been closed...</td>\n",
       "      <td>Mildred Olima</td>\n",
       "      <td>2022-09-18 18:46:23.717</td>\n",
       "      <td>Closed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mildred Olima</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-FY23</td>\n",
       "      <td>Customer Loyalty Program Management Processes...</td>\n",
       "      <td>Requires attention (75%)</td>\n",
       "      <td>FY23 Audit plan</td>\n",
       "      <td>Q1</td>\n",
       "      <td>CONSUMER BUSINESS</td>\n",
       "      <td>Annual Audit Plan</td>\n",
       "      <td>Finalised</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>...</td>\n",
       "      <td>•The new customer onboarding communication has...</td>\n",
       "      <td>Awuor Lourrine Juliet</td>\n",
       "      <td>2022-09-28 08:16:00.680</td>\n",
       "      <td>Closed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Awuor Lourrine Juliet</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProjectCode                                       ProjectTitle  \\\n",
       "0      3-FY23   Customer Loyalty Program Management Processes...   \n",
       "1      3-FY23   Customer Loyalty Program Management Processes...   \n",
       "2      3-FY23   Customer Loyalty Program Management Processes...   \n",
       "3      3-FY23   Customer Loyalty Program Management Processes...   \n",
       "4      3-FY23   Customer Loyalty Program Management Processes...   \n",
       "\n",
       "               ProjectScore   AuditPlanTitle ProjectQuarter  \\\n",
       "0  Requires attention (75%)  FY23 Audit plan             Q1   \n",
       "1  Requires attention (75%)  FY23 Audit plan             Q1   \n",
       "2  Requires attention (75%)  FY23 Audit plan             Q1   \n",
       "3  Requires attention (75%)  FY23 Audit plan             Q1   \n",
       "4  Requires attention (75%)  FY23 Audit plan             Q1   \n",
       "\n",
       "            Division      ProjectSource ProjectPhase  \\\n",
       "0  CONSUMER BUSINESS  Annual Audit Plan    Finalised   \n",
       "1  CONSUMER BUSINESS  Annual Audit Plan    Finalised   \n",
       "2  CONSUMER BUSINESS  Annual Audit Plan    Finalised   \n",
       "3  CONSUMER BUSINESS  Annual Audit Plan    Finalised   \n",
       "4  CONSUMER BUSINESS  Annual Audit Plan    Finalised   \n",
       "\n",
       "  ProjectScheduledStartDate ProjectScheduledEndDate  ...  \\\n",
       "0                2022-04-04              2022-06-10  ...   \n",
       "1                2022-04-04              2022-06-10  ...   \n",
       "2                2022-04-04              2022-06-10  ...   \n",
       "3                2022-04-04              2022-06-10  ...   \n",
       "4                2022-04-04              2022-06-10  ...   \n",
       "\n",
       "                                    LastStatusUpdate   LastStatusUpdateUser  \\\n",
       "0  Update from Lilian Nyambu- For the implementat...  Awuor Lourrine Juliet   \n",
       "1  The large SME customers with fixed services we...          Mildred Olima   \n",
       "2  The customer journey was reviewed and revised ...  Awuor Lourrine Juliet   \n",
       "3  The churned customer accounts have been closed...          Mildred Olima   \n",
       "4  •The new customer onboarding communication has...  Awuor Lourrine Juliet   \n",
       "\n",
       "     LastStatusUpdateDate OverdueDescription OverdueStatus OverdueDays  \\\n",
       "0 2023-04-03 12:12:22.630             Closed             0           0   \n",
       "1 2023-03-27 07:56:57.980             Closed             0           0   \n",
       "2 2023-11-01 14:42:51.113             Closed             0           0   \n",
       "3 2022-09-18 18:46:23.717             Closed             0           0   \n",
       "4 2022-09-28 08:16:00.680             Closed             0           0   \n",
       "\n",
       "                 Auditor IssueOwner SeniorManager   HOD  \n",
       "0  Awuor Lourrine Juliet       None          None  None  \n",
       "1  Awuor Lourrine Juliet       None          None  None  \n",
       "2          Mildred Olima       None          None  None  \n",
       "3          Mildred Olima       None          None  None  \n",
       "4  Awuor Lourrine Juliet       None          None  None  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=query_tool(query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39208e28-3cb8-4002-8861-db198ea7db3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProjectCode', 'ProjectTitle', 'ProjectScore', 'AuditPlanTitle',\n",
       "       'ProjectQuarter', 'Division', 'ProjectSource', 'ProjectPhase',\n",
       "       'ProjectScheduledStartDate', 'ProjectScheduledEndDate', 'IssueTitle',\n",
       "       'RiskRating', 'IssueReleased', 'IssueReleaseDate', 'IssueState',\n",
       "       'RecommendationTitle', 'ManagementAction', 'DueDate', 'ReviewDueDate',\n",
       "       'RecommendationDivision', 'RecommendationState', 'TrackingStatus',\n",
       "       'LastStatusUpdate', 'LastStatusUpdateUser', 'LastStatusUpdateDate',\n",
       "       'OverdueDescription', 'OverdueStatus', 'OverdueDays', 'Auditor',\n",
       "       'IssueOwner', 'SeniorManager', 'HOD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c77ce2bd-2488-44a2-ac4b-6112d7e4518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_tokenize_internal: Added a BOS token to the prompt as specified by the model but the prompt also starts with a BOS token. So now the final prompt starts with 2 BOS tokens. Are you sure this is what you want?\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10763.66 ms\n",
      "llama_print_timings:      sample time =      14.54 ms /   166 runs   (    0.09 ms per token, 11416.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7968.66 ms /   188 tokens (   42.39 ms per token,    23.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10030.94 ms /   165 runs   (   60.79 ms per token,    16.45 tokens per second)\n",
      "llama_print_timings:       total time =   18117.93 ms /   353 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Develop an enterprise loyalty program tailored for defending market share against competitors.\n",
      "\n",
      "2. Implement a customer portal that allows for easy initiation of loyalty programs by customers.\n",
      "\n",
      "3. Establish policies and mechanisms to ensure the timely expiry of loyalty values, thus preventing churn due to dormant accounts.\n",
      "\n",
      "4. Revamp the brand's message and program for kindergartens to resonate with target demographics effectively.\n",
      "\n",
      "5. Develop a systematic process to track and guarantee the successful delivery of solutions, ensuring customer satisfaction and retention.\n",
      "\n",
      "6. Redesign the redemption process at 'bonga everywhere', making it more user-friendly and efficient for consumers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(str(llm.complete(f'can you share a list of only critical recommendations for higher level leadership from {df[[\"RecommendationTitle\"]]}. \\\n",
    "Check if recommendations can be merged and merge them if they will refer to largely similar recommendations at a high level. \\\n",
    "Do not share any other explanation text or notes or anything else, only a list of the issues/merged recommendations and everything should be numbered, if its not numbered drop it')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c98c29d3-c8ac-4fab-8f5a-65232387008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_tokenize_internal: Added a BOS token to the prompt as specified by the model but the prompt also starts with a BOS token. So now the final prompt starts with 2 BOS tokens. Are you sure this is what you want?\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10763.66 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    99 runs   (    0.09 ms per token, 11374.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5913.85 ms /   181 tokens (   32.67 ms per token,    30.61 tokens per second)\n",
      "llama_print_timings:        eval time =    5563.45 ms /    98 runs   (   56.77 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:       total time =   11541.00 ms /   279 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Customer segments not adequately covered by loyalty programs\n",
      "\n",
      "2. Enterprise customers lacking self-service options\n",
      "\n",
      "3. Loyalty points for enterprise customers remaining unexpired\n",
      "\n",
      "4. Low enrollment of new customers in loyalty programs\n",
      "\n",
      "5. Payment issues related to full license fees for a system underdevelopment\n",
      "\n",
      "6. Reconciliation discrepancies on merchandised bonga products\n"
     ]
    }
   ],
   "source": [
    "print(str(llm.complete(f'can you share a list of only critical issues for higher level leadership from {df[[\"IssueTitle\"]]}. \\\n",
    "Check if issues can be merged and merge them if they will refer to largely similar issue at a high level. \\\n",
    "Do not share any other explanation text or notes or anything else, only a list of the issues/merged issues and everything should be numbered, if its not numbered drop it')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "54319d0a-80af-47b1-aa87-1a102755374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_tokenize_internal: Added a BOS token to the prompt as specified by the model but the prompt also starts with a BOS token. So now the final prompt starts with 2 BOS tokens. Are you sure this is what you want?\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10763.66 ms\n",
      "llama_print_timings:      sample time =      10.90 ms /    94 runs   (    0.12 ms per token,  8624.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8585.05 ms /    80 tokens (  107.31 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:        eval time =   43037.85 ms /    93 runs   (  462.77 ms per token,     2.16 tokens per second)\n",
      "llama_print_timings:       total time =   51855.21 ms /   173 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 1. Uncovered customer segments by loyalty program\\n\\n2. Lack of enterprise-specific loyalty features\\n\\n3. Premature expiration of loyalty points for customers\\n\\n4. Insufficient new customer enrollments in the loyalty program\\n\\n5. Full license fees not paid, undermining system integrity\\n\\n6. Discrepancies detected during merchandise-related reconciliations'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues=str(llm.complete(f'can you share a list of only critical issues for higher level leadership from {df[[\"IssueTitle\"]]}. \\\n",
    "Check if issues can be merged and merge them if they will refer to largely similar issue at a high level. \\\n",
    "Do not share any other explanation text or notes or anything else, only a list of the issues/merged issues and everything should be numbered, if its not numbered drop it'))\n",
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "a7c11099-60ed-474e-9051-0bedbb457079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Uncovered customer segments by loyalty program',\n",
       " 'Lack of enterprise-specific loyalty features',\n",
       " 'Premature expiration of loyalty points for customers',\n",
       " 'Insufficient new customer enrollments in the loyalty program',\n",
       " 'Full license fees not paid, undermining system integrity',\n",
       " 'Discrepancies detected during merchandise-related reconciliations']"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_issues(text):\n",
    "    # Split the text by newline characters and filter out empty strings\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    \n",
    "    # Extract the issue descriptions by removing the numbering and trimming whitespace\n",
    "    issues = []\n",
    "    for line in lines:\n",
    "        if line[0].isdigit() and '.' in line:\n",
    "            issue = line.split('.', 1)[1].strip()\n",
    "            issues.append(issue)\n",
    "    \n",
    "    return issues\n",
    "\n",
    "issues=extract_issues(issues)\n",
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6758ee00-5d0f-4503-b1d9-bb466dc0869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name=df['ProjectTitle'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fa2fc26b-b41a-4fec-b023-821359748233",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_report=pd.to_datetime('today').strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "18c7b6a3-4f2c-4633-b503-6a868fc667c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProjectCode', 'ProjectTitle', 'ProjectScore', 'AuditPlanTitle',\n",
       "       'ProjectQuarter', 'Division', 'ProjectSource', 'ProjectPhase',\n",
       "       'ProjectScheduledStartDate', 'ProjectScheduledEndDate', 'IssueTitle',\n",
       "       'RiskRating', 'IssueReleased', 'IssueReleaseDate', 'IssueState',\n",
       "       'RecommendationTitle', 'ManagementAction', 'DueDate', 'ReviewDueDate',\n",
       "       'RecommendationDivision', 'RecommendationState', 'TrackingStatus',\n",
       "       'LastStatusUpdate', 'LastStatusUpdateUser', 'LastStatusUpdateDate',\n",
       "       'OverdueDescription', 'OverdueStatus', 'OverdueDays', 'Auditor',\n",
       "       'IssueOwner', 'SeniorManager', 'HOD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "76d951e0-a786-41c1-a56d-3663a1e615b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chief=f\"CHIEF {df['Division'].unique()[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "843b7780-1d6e-488d-9bf6-f726d2171d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_code=df['ProjectCode'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a4e41-25e5-478f-8506-8cac3268bbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b4e65930-0b87-46ca-a572-280e1410a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_text(prompt, max_tokens=15000):\n",
    "    response = llm.complete(\n",
    "        prompt=prompt\n",
    "    )\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b243faba-9d25-477e-99cf-699aff022bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chart.png'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "def create_chart():\n",
    "    # Example chart creation using Matplotlib\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    categories = ['A', 'B', 'C', 'D']\n",
    "    values = [4, 7, 1, 8]\n",
    "    plt.bar(categories, values, color='blue')\n",
    "    plt.title('Example Chart')\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Values')\n",
    "    chart_path = 'chart.png'\n",
    "    plt.savefig(chart_path)\n",
    "    plt.close()\n",
    "    return chart_path\n",
    "create_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f15c74-2d76-4b5b-940e-eea49ca12e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caae98c-cc34-43ac-9da5-fbaddd621dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8eb5359c-3602-4c4a-aa1e-6352cc7fa9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from docx import Document\n",
    "# from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "# from docx.shared import Pt, RGBColor, Inches\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from docx.oxml import OxmlElement\n",
    "# from docx.oxml.ns import qn\n",
    "\n",
    "# def set_cell_shading(cell, shading_color):\n",
    "#     \"\"\"Set shading (background color) for a table cell.\"\"\"\n",
    "#     tc = cell._element\n",
    "#     tcPr = tc.get_or_add_tcPr()\n",
    "#     shd = OxmlElement('w:shd')\n",
    "#     shd.set(qn('w:val'), 'clear')\n",
    "#     shd.set(qn('w:color'), 'auto')\n",
    "#     shd.set(qn('w:fill'), shading_color)\n",
    "#     tcPr.append(shd)\n",
    "\n",
    "# def highlight_row(table, row_idx, shading_color):\n",
    "#     \"\"\"Highlight a specific row in a table.\"\"\"\n",
    "#     row = table.rows[row_idx]\n",
    "#     for cell in row.cells:\n",
    "#         set_cell_shading(cell, shading_color)\n",
    "\n",
    "# def load_template(template_path):\n",
    "#     return Document(template_path)\n",
    "\n",
    "# def format_run(run, font_size=None, font_color=None, bold=None, italic=None):\n",
    "#     if font_size:\n",
    "#         run.font.size = Pt(font_size)\n",
    "#     if font_color:\n",
    "#         run.font.color.rgb = RGBColor(*font_color)\n",
    "#     if bold is not None:\n",
    "#         run.bold = bold\n",
    "#     if italic is not None:\n",
    "#         run.italic = italic\n",
    "\n",
    "# def replace_placeholder(paragraph, placeholder, content, font_size=None, font_color=None, bold=None, italic=None):\n",
    "#     if placeholder in paragraph.text:\n",
    "#         inline = paragraph.runs\n",
    "#         for item in inline:\n",
    "#             if placeholder in item.text:\n",
    "#                 item.text = item.text.replace(placeholder, content)\n",
    "#                 format_run(item, font_size, font_color, bold, italic)\n",
    "\n",
    "# def populate_template(doc, data):\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         for key, value in data.items():\n",
    "#             replace_placeholder(paragraph, key, value['text'], value.get('font_size'), value.get('font_color'), value.get('bold'), value.get('italic'))\n",
    "#     for table in doc.tables:\n",
    "#         for row in table.rows:\n",
    "#             for cell in row.cells:\n",
    "#                 for paragraph in cell.paragraphs:\n",
    "#                     for key, value in data.items():\n",
    "#                         replace_placeholder(paragraph, key, value['text'], value.get('font_size'), value.get('font_color'), value.get('bold'), value.get('italic'))\n",
    "#     return doc\n",
    "\n",
    "# def populate_table_with_placeholder(doc, placeholder, content):\n",
    "#     \"\"\"Populate table cells containing a specific placeholder with content.\"\"\"\n",
    "#     for table in doc.tables:\n",
    "#         for row in table.rows:\n",
    "#             for cell in row.cells:\n",
    "#                 for paragraph in cell.paragraphs:\n",
    "#                     replace_placeholder(paragraph, placeholder, content)\n",
    "\n",
    "\n",
    "# # def add_table_of_contents(doc):\n",
    "# #     toc_paragraph = doc.add_paragraph()\n",
    "# #     run = toc_paragraph.add_run()\n",
    "# #     fldChar = docx.oxml.OxmlElement('w:fldChar')\n",
    "# #     fldChar.set(docx.oxml.ns.qn('w:fldCharType'), 'begin')\n",
    "# #     instrText = docx.oxml.OxmlElement('w:instrText')\n",
    "# #     instrText.set(docx.oxml.ns.qn('xml:space'), 'preserve')\n",
    "# #     instrText.text = 'TOC \\\\o \"1-3\" \\\\h \\\\z \\\\u'\n",
    "# #     fldChar2 = docx.oxml.OxmlElement('w:fldChar')\n",
    "# #     fldChar2.set(docx.oxml.ns.qn('w:fldCharType'), 'separate')\n",
    "# #     fldChar3 = docx.oxml.OxmlElement('w:fldChar')\n",
    "# #     fldChar3.set(docx.oxml.ns.qn('w:fldCharType'), 'end')\n",
    "# #     run._r.append(fldChar)\n",
    "# #     run._r.append(instrText)\n",
    "# #     run._r.append(fldChar2)\n",
    "# #     run._r.append(fldChar3)\n",
    "\n",
    "# def add_table_of_contents(doc):\n",
    "#     # Create a new paragraph for the TOC\n",
    "#     toc_paragraph = doc.add_paragraph()\n",
    "#     run = toc_paragraph.add_run()\n",
    "    \n",
    "#     # Create the field begin element\n",
    "#     fldChar1 = OxmlElement('w:fldChar')\n",
    "#     fldChar1.set(qn('w:fldCharType'), 'begin')\n",
    "    \n",
    "#     # Create the field instruction element\n",
    "#     instrText = OxmlElement('w:instrText')\n",
    "#     instrText.set(qn('xml:space'), 'preserve')\n",
    "#     instrText.text = 'TOC \\\\o \"1-3\" \\\\h \\\\z \\\\u'\n",
    "    \n",
    "#     # Create the field separate element\n",
    "#     fldChar2 = OxmlElement('w:fldChar')\n",
    "#     fldChar2.set(qn('w:fldCharType'), 'separate')\n",
    "    \n",
    "#     # Create the field end element\n",
    "#     fldChar3 = OxmlElement('w:fldChar')\n",
    "#     fldChar3.set(qn('w:fldCharType'), 'end')\n",
    "    \n",
    "#     # Add the elements to the run\n",
    "#     run._r.append(fldChar1)\n",
    "#     run._r.append(instrText)\n",
    "#     run._r.append(fldChar2)\n",
    "#     run._r.append(fldChar3)\n",
    "# def save_document(doc, output_path):\n",
    "#     doc.save(output_path)\n",
    "\n",
    "# def create_chart(chart_number):\n",
    "#     # Example chart creation using Matplotlib\n",
    "#     plt.figure(figsize=(4, 3))  # Default size, can be adjusted for specific charts\n",
    "#     categories = ['A', 'B', 'C', 'D']\n",
    "#     if chart_number == 1:\n",
    "#         values = [4, 7, 1, 8]\n",
    "#         plt.bar(categories, values, color='blue')\n",
    "#         plt.title('Summary of Observations')\n",
    "#     elif chart_number == 2:\n",
    "#         values = [3, 6, 2, 9]\n",
    "#         plt.bar(categories, values, color='green')\n",
    "#         plt.title('Distribution of Observations per Scope Area')\n",
    "#     elif chart_number == 3:\n",
    "#         values = [5, 2, 3, 7]\n",
    "#         plt.bar(categories, values, color='red')\n",
    "#         plt.title('Root Cause Analysis of Findings')\n",
    "#     plt.xlabel('Categories')\n",
    "#     plt.ylabel('Values')\n",
    "#     chart_path = f'chart_{chart_number}.png'\n",
    "#     plt.savefig(chart_path)\n",
    "#     plt.close()\n",
    "#     return chart_path\n",
    "\n",
    "# def insert_charts_side_by_side(doc, chart_paths, sizes, placeholder):\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         if placeholder in paragraph.text:\n",
    "#             p = paragraph._element\n",
    "#             p.clear()  # Clear the placeholder text\n",
    "\n",
    "#             table = doc.add_table(rows=1, cols=len(chart_paths))\n",
    "#             for i, chart_path in enumerate(chart_paths):\n",
    "#                 cell = table.cell(0, i)\n",
    "#                 run = cell.paragraphs[0].add_run()\n",
    "#                 width, height = sizes[i]\n",
    "#                 run.add_picture(chart_path, width=Inches(width), height=Inches(height))\n",
    "#                 cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "#             p.addnext(table._element)  # Insert the table after the paragraph\n",
    "#             return\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     template_path = 'Audit Report Template.docx'  # Path to the provided template\n",
    "#     output_path = 'Populated_Audit_Report.docx'\n",
    "    \n",
    "#     # Generate content for various sections\n",
    "#     title = project_name.strip()\n",
    "#     background = \"Provide background information for the audit report.\"\n",
    "#     objectives = \"State the overall objectives of the audit.\"\n",
    "#     scope = \"Describe the scope of the audit.\"\n",
    "#     opinion = \"Provide an audit opinion.\"\n",
    "#     executive_summary = \"Write an executive summary with key highlights.\"\n",
    "#     detailed_issues = \"Describe detailed improvement opportunities and issues.\"\n",
    "#     chief_name_title = \"John Doe – Chief Audit Executive\"\n",
    "\n",
    "#     # Data to populate the template\n",
    "#     #000- black\n",
    "#     #00255 blue\n",
    "#     data = {\n",
    "#         'Audit Code':{'text':audit_code,'font_size': 18, 'font_color': (255, 255, 255), 'bold': True, 'italic': False}, \n",
    "#         'Project Title': {'text': title, 'font_size': 28, 'font_color': (255, 255, 255), 'bold': True, 'italic': False},\n",
    "#         'XXXX': {'text': background, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "#         'Overall objectives': {'text': objectives, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "#         'Scope': {'text': scope, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "#         'Opinion and grading': {'text': opinion, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "#         'EXECUTIVE SUMMARY: Key highlights': {'text': executive_summary, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "#         'Description of Issue 1.': {'text': detailed_issues, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "#         'Report_Date': {'text': date_report, 'font_size': 18, 'font_color': (255, 255, 255), 'bold': False, 'italic': False},\n",
    "#         'Chief Name':{'text': chief, 'font_size': 12.5, 'font_color': (255, 255, 255), 'bold': False, 'italic': False},\n",
    "#         'Issue_things':{'text': 'kajgfkalgFJKGKLADFGligfiuEGFUWIEG', 'font_size': 12.5, 'font_color': (255, 255, 255), 'bold': False, 'italic': False}\n",
    "#     }\n",
    "    \n",
    "#     # Load, populate and add TOC to the document\n",
    "#     doc = load_template(template_path)\n",
    "#     doc = populate_template(doc, data)\n",
    "#     add_table_of_contents(doc)\n",
    "    \n",
    "#     # Create charts\n",
    "#     chart_path_1 = create_chart(1)\n",
    "#     chart_path_2 = create_chart(2)\n",
    "#     chart_path_3 = create_chart(3)\n",
    "    \n",
    "#     # Define chart sizes (width, height in inches)\n",
    "#     sizes = [(3, 2), (4, 2), (2, 2)]  # Chart 1: 3x2, Chart 2: 4x2, Chart 3: 2x2\n",
    "    \n",
    "#     # Insert charts side-by-side in a table\n",
    "#     insert_charts_side_by_side(doc, [chart_path_1, chart_path_2, chart_path_3], sizes, 'Chart1')\n",
    "\n",
    "#     # Find the table to modify (assuming the first table here)\n",
    "#     table = doc.tables[2]\n",
    "    \n",
    "#     # Highlight the third row (index 2)\n",
    "#     highlight_row(table, 2, '#FF0000')  # Yellow highlight (hex color code)\n",
    "\n",
    "#         # Placeholder and content to replace\n",
    "#     placeholder = 'ISSUES'\n",
    "#     content = 'New issue content that replaces the placeholder text.'\n",
    "    \n",
    "#     # Populate the placeholder in table cells\n",
    "#     populate_table_with_placeholder(doc, placeholder, content)\n",
    "#     populate_table_with_placeholder(doc, 'RISKS', content)\n",
    "#     populate_table_with_placeholder(doc, 'RATINGS', 'MEDIUM')\n",
    "#     # Save the document\n",
    "#     save_document(doc, output_path)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796efadd-518b-41c6-82ec-63b3d176f8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8cd7a1-870b-449f-a640-c4438b60f9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a9500-ca56-462f-80a2-521d75cae052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "4b0b034c-e713-4f23-b04a-187a40ef80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_placeholder_in_paragraph(paragraph, placeholders):\n",
    "    for run in paragraph.runs:\n",
    "        for key, value in placeholders.items():\n",
    "            if key in run.text:\n",
    "                run.text = run.text.replace(key, value)\n",
    "\n",
    "def replace_placeholders_in_table(table, placeholders):\n",
    "    \"\"\"Replace placeholders in a table with item-specific data.\"\"\"\n",
    "    for row in table.rows:\n",
    "        for cell in row.cells:\n",
    "            for paragraph in cell.paragraphs:\n",
    "                replace_placeholder_in_paragraph(paragraph, placeholders)\n",
    "\n",
    "def find_paragraph_before_table(doc, table):\n",
    "    \"\"\"Find the paragraph that immediately precedes the specified table.\"\"\"\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph._element.getnext() is table._element:\n",
    "            return paragraph\n",
    "    return None\n",
    "\n",
    "def clone_section_with_content(template_paragraph, template_table, placeholders):\n",
    "    \"\"\"Clone the title and table, then replace placeholders.\"\"\"\n",
    "    cloned_paragraph = deepcopy(template_paragraph)\n",
    "    replace_placeholder_in_paragraph(cloned_paragraph, placeholders)\n",
    "    \n",
    "    cloned_table = deepcopy(template_table)\n",
    "    replace_placeholders_in_table(cloned_table, placeholders)\n",
    "    \n",
    "    return cloned_paragraph, cloned_table\n",
    "\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.shared import Pt, RGBColor, Inches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from docx.oxml import OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "\n",
    "def set_cell_shading(cell, shading_color):\n",
    "    \"\"\"Set shading (background color) for a table cell.\"\"\"\n",
    "    tc = cell._element\n",
    "    tcPr = tc.get_or_add_tcPr()\n",
    "    shd = OxmlElement('w:shd')\n",
    "    shd.set(qn('w:val'), 'clear')\n",
    "    shd.set(qn('w:color'), 'auto')\n",
    "    shd.set(qn('w:fill'), shading_color)\n",
    "    tcPr.append(shd)\n",
    "\n",
    "def highlight_row(table, row_idx, shading_color):\n",
    "    \"\"\"Highlight a specific row in a table.\"\"\"\n",
    "    row = table.rows[row_idx]\n",
    "    for cell in row.cells:\n",
    "        set_cell_shading(cell, shading_color)\n",
    "\n",
    "def load_template(template_path):\n",
    "    return Document(template_path)\n",
    "\n",
    "def format_run(run, font_size=None, font_color=None, bold=None, italic=None):\n",
    "    if font_size:\n",
    "        run.font.size = Pt(font_size)\n",
    "    if font_color:\n",
    "        run.font.color.rgb = RGBColor(*font_color)\n",
    "    if bold is not None:\n",
    "        run.bold = bold\n",
    "    if italic is not None:\n",
    "        run.italic = italic\n",
    "\n",
    "def replace_placeholder(paragraph, placeholder, content, font_size=None, font_color=None, bold=None, italic=None):\n",
    "    if placeholder in paragraph.text:\n",
    "        inline = paragraph.runs\n",
    "        for item in inline:\n",
    "            if placeholder in item.text:\n",
    "                item.text = item.text.replace(placeholder, content)\n",
    "                format_run(item, font_size, font_color, bold, italic)\n",
    "\n",
    "def populate_template(doc, data):\n",
    "    for paragraph in doc.paragraphs:\n",
    "        for key, value in data.items():\n",
    "            replace_placeholder(paragraph, key, value['text'], value.get('font_size'), value.get('font_color'), value.get('bold'), value.get('italic'))\n",
    "    for table in doc.tables:\n",
    "        for row in table.rows:\n",
    "            for cell in row.cells:\n",
    "                for paragraph in cell.paragraphs:\n",
    "                    for key, value in data.items():\n",
    "                        replace_placeholder(paragraph, key, value['text'], value.get('font_size'), value.get('font_color'), value.get('bold'), value.get('italic'))\n",
    "    return doc\n",
    "\n",
    "def populate_table_with_placeholder(doc, placeholder, content):\n",
    "    \"\"\"Populate table cells containing a specific placeholder with content.\"\"\"\n",
    "    for table in doc.tables:\n",
    "        for row in table.rows:\n",
    "            for cell in row.cells:\n",
    "                for paragraph in cell.paragraphs:\n",
    "                    replace_placeholder(paragraph, placeholder, content)\n",
    "\n",
    "\n",
    "\n",
    "def add_table_of_contents(doc):\n",
    "    # Create a new paragraph for the TOC\n",
    "    toc_paragraph = doc.add_paragraph()\n",
    "    run = toc_paragraph.add_run()\n",
    "    \n",
    "    # Create the field begin element\n",
    "    fldChar1 = OxmlElement('w:fldChar')\n",
    "    fldChar1.set(qn('w:fldCharType'), 'begin')\n",
    "    \n",
    "    # Create the field instruction element\n",
    "    instrText = OxmlElement('w:instrText')\n",
    "    instrText.set(qn('xml:space'), 'preserve')\n",
    "    instrText.text = 'TOC \\\\o \"1-3\" \\\\h \\\\z \\\\u'\n",
    "    \n",
    "    # Create the field separate element\n",
    "    fldChar2 = OxmlElement('w:fldChar')\n",
    "    fldChar2.set(qn('w:fldCharType'), 'separate')\n",
    "    \n",
    "    # Create the field end element\n",
    "    fldChar3 = OxmlElement('w:fldChar')\n",
    "    fldChar3.set(qn('w:fldCharType'), 'end')\n",
    "    \n",
    "    # Add the elements to the run\n",
    "    run._r.append(fldChar1)\n",
    "    run._r.append(instrText)\n",
    "    run._r.append(fldChar2)\n",
    "    run._r.append(fldChar3)\n",
    "def save_document(doc, output_path):\n",
    "    doc.save(output_path)\n",
    "\n",
    "def create_chart(chart_number):\n",
    "    # Example chart creation using Matplotlib\n",
    "    plt.figure(figsize=(4, 3))  # Default size, can be adjusted for specific charts\n",
    "    categories = ['A', 'B', 'C', 'D']\n",
    "    if chart_number == 1:\n",
    "        values = [4, 7, 1, 8]\n",
    "        plt.bar(categories, values, color='blue')\n",
    "        plt.title('Summary of Observations')\n",
    "    elif chart_number == 2:\n",
    "        values = [3, 6, 2, 9]\n",
    "        plt.bar(categories, values, color='green')\n",
    "        plt.title('Distribution of Observations per Scope Area')\n",
    "    elif chart_number == 3:\n",
    "        values = [5, 2, 3, 7]\n",
    "        plt.bar(categories, values, color='red')\n",
    "        plt.title('Root Cause Analysis of Findings')\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Values')\n",
    "    chart_path = f'chart_{chart_number}.png'\n",
    "    plt.savefig(chart_path)\n",
    "    plt.close()\n",
    "    return chart_path\n",
    "\n",
    "def insert_charts_side_by_side(doc, chart_paths, sizes, placeholder):\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if placeholder in paragraph.text:\n",
    "            p = paragraph._element\n",
    "            p.clear()  # Clear the placeholder text\n",
    "\n",
    "            table = doc.add_table(rows=1, cols=len(chart_paths))\n",
    "            for i, chart_path in enumerate(chart_paths):\n",
    "                cell = table.cell(0, i)\n",
    "                run = cell.paragraphs[0].add_run()\n",
    "                width, height = sizes[i]\n",
    "                run.add_picture(chart_path, width=Inches(width), height=Inches(height))\n",
    "                cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "            p.addnext(table._element)  # Insert the table after the paragraph\n",
    "            return\n",
    "\n",
    "\n",
    "def main():\n",
    "    template_path = 'Audit Report Template.docx'  # Path to the provided template\n",
    "    output_path = 'Populated_Audit_Report.docx'\n",
    "    \n",
    "    # Generate content for various sections\n",
    "    title = project_name.strip()\n",
    "    background = \"Provide background information for the audit report.\"\n",
    "    objectives = \"State the overall objectives of the audit.\"\n",
    "    scope = \"Describe the scope of the audit.\"\n",
    "    opinion = \"Provide an audit opinion.\"\n",
    "    executive_summary = \"Write an executive summary with key highlights.\"\n",
    "    detailed_issues = \"Describe detailed improvement opportunities and issues.\"\n",
    "    chief_name_title = \"John Doe – Chief Audit Executive\"\n",
    "\n",
    "    # Data to populate the template\n",
    "    #000- black\n",
    "    #00255 blue\n",
    "    data = {\n",
    "        'Audit Code':{'text':audit_code,'font_size': 18, 'font_color': (255, 255, 255), 'bold': True, 'italic': False}, \n",
    "        'Project Title': {'text': title, 'font_size': 28, 'font_color': (255, 255, 255), 'bold': True, 'italic': False},\n",
    "        'XXXX': {'text': background, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "        'Overall objectives': {'text': objectives, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "        'Scope': {'text': scope, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "        'Opinion and grading': {'text': opinion, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "        'EXECUTIVE SUMMARY: Key highlights': {'text': executive_summary, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "        'Description of Issue 1.': {'text': detailed_issues, 'font_size': 12, 'font_color': (0, 0, 0), 'bold': False, 'italic': False},\n",
    "        'Report_Date': {'text': date_report, 'font_size': 18, 'font_color': (255, 255, 255), 'bold': False, 'italic': False},\n",
    "        'Chief Name':{'text': chief, 'font_size': 12.5, 'font_color': (255, 255, 255), 'bold': False, 'italic': False}\n",
    "    }\n",
    "    \n",
    "    # Load, populate and add TOC to the document\n",
    "    doc = load_template(template_path)\n",
    "\n",
    "    \n",
    "    # Create charts\n",
    "    chart_path_1 = create_chart(1)\n",
    "    chart_path_2 = create_chart(2)\n",
    "    chart_path_3 = create_chart(3)\n",
    "    \n",
    "    # Define chart sizes (width, height in inches)\n",
    "    sizes = [(2, 2), (4, 2), (2, 2)]  # Chart 1: 2x2, Chart 2: 4x2, Chart 3: 2x2\n",
    "    \n",
    "    # Insert charts side-by-side in a table\n",
    "    insert_charts_side_by_side(doc, [chart_path_1, chart_path_2, chart_path_3], sizes, 'Chart1')\n",
    "\n",
    "    # Find the table to modify (assuming the first table here)\n",
    "    table = doc.tables[2]\n",
    "    \n",
    "    # Highlight the third row (index 2)\n",
    "    highlight_row(table, 2, '#FF0000')  # Yellow highlight (hex color code)\n",
    "\n",
    "        # Placeholder and content to replace\n",
    "    placeholder = 'ISSUES'\n",
    "    placeholder1 = 'RISKS'\n",
    "    placeholder2 = 'RATINGS'\n",
    "    placeholder3='RECOM'\n",
    "    content = 'New issue content that replaces the placeholder text.'\n",
    "\n",
    "      # Example issues data\n",
    "    # issues = [\n",
    "    #     {placeholder: \"Issue description for no campaigns\", \"Description_of_Issue\": \"Description of Issue for no_campaigns\",placeholder1: \"no_campaign\",placeholder2:\"no_campaign_rating\",placeholder3:\"recoms_no_campaign\"},\n",
    "    #     {placeholder: \"Issue description for poor engagement\", \"Description_of_Issue\": \"Description of Issue for poor_engagement\",placeholder1: \"poor_engagement\",placeholder2:\"poor_engagement_rating\",placeholder3:\"recoms_poor_engag\"},\n",
    "    #     {placeholder: \"Issue description for low conversion\", \"Description_of_Issue\": \"Description of Issue for low_conversion\",placeholder1: \"low_conversion\",placeholder2:\"low_conversion_rating\",placeholder3:\"recoms_low_conversion\"}\n",
    "    # ]\n",
    "    issues1=[]\n",
    "    for i in issues:\n",
    "        issues1.append({placeholder: i, \"Description_of_Issue\": f\"Description of Issue for {i}\",\\\n",
    "             placeholder1: f\"risk {i}\",placeholder2:f\"{i}_rating\",placeholder3:f\"{i}_recom\"})\n",
    "    \n",
    "    # Locate the template table (assuming it's the first table in the document)\n",
    "    template_table_index = 4  # Adjust this index based on where your template table is located\n",
    "    template_table = doc.tables[template_table_index]\n",
    "\n",
    "    # Locate the paragraph immediately preceding the table\n",
    "    template_paragraph = find_paragraph_before_table(doc, template_table)\n",
    "\n",
    "    if template_paragraph is None:\n",
    "        print(\"No paragraph found associated with the specified table.\")\n",
    "        return\n",
    "\n",
    "    # Remove the original template elements\n",
    "    doc.element.body.remove(template_table._element)\n",
    "    doc.element.body.remove(template_paragraph._element)\n",
    "    \n",
    "    # Clone and fill the section for each issue\n",
    "    for issue in issues1:\n",
    "        placeholders = {\n",
    "            \"Description of Issue\": issue[\"Description_of_Issue\"],\n",
    "            placeholder: issue[placeholder],\n",
    "            placeholder1: issue[placeholder1],\n",
    "            placeholder2: issue[placeholder2],\n",
    "            placeholder3: issue[placeholder3]\n",
    "        }\n",
    "        \n",
    "        cloned_paragraph, cloned_table = clone_section_with_content(template_paragraph, template_table, placeholders)\n",
    "        \n",
    "        # Append the cloned elements to the document\n",
    "        doc.element.body.append(cloned_paragraph._element)\n",
    "        doc.element.body.append(cloned_table._element)\n",
    "        \n",
    "        # Add a paragraph to separate sections\n",
    "        doc.add_paragraph()\n",
    "\n",
    "    \n",
    "    # Populate the placeholder in table cells\n",
    "    populate_table_with_placeholder(doc, 'Issue description for no campaigns', 'trail of stuff')\n",
    "    # populate_table_with_placeholder(doc, 'RISKS', content)\n",
    "    # populate_table_with_placeholder(doc, 'RATINGS', 'MEDIUM')\n",
    "\n",
    "    doc = populate_template(doc, data)\n",
    "    add_table_of_contents(doc)\n",
    "    # Save the document\n",
    "    save_document(doc, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1dbb15-8964-4adb-ab68-d21d3126871d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f92f281-3829-43b0-912b-6583feeb4cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b193448-2d13-4c73-8b32-85f360991519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476694c-b8c8-43b6-9e64-dcc0b41bf947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ca7d1-2fea-460c-a814-2143f4676c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4f059-c085-47f1-9c85-b5046e74d203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f96a3d-e46b-4375-9096-e9ddd6475ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b49959-63c9-4b98-be30-64d44054b0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd3162-6318-4e31-a9b8-d052286fc439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d9b4f9-7702-4c4b-a27c-03740e351022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb636f-162f-4b6f-8e4b-4264dae3ef9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0426aa49-6ef2-4730-af95-499d340edab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_str = (\n",
    "    \"1. Convert the query to executable Python code using Pandas.\\n\"\n",
    "    \"2. The final line of code should be a Python expression that can be called with the `eval()` function.\\n\"\n",
    "    \"3. The code should represent a solution to the query.\\n\"\n",
    "    \"4. PRINT ONLY THE EXPRESSION.\\n\"\n",
    "    \"5. Do not quote the expression.\\n\"\n",
    ")\n",
    "\n",
    "pandas_prompt_str = (\n",
    "    \"You are working with a pandas dataframe in Python.\\n\"\n",
    "    \"The name of the dataframe is `df`.\\n\"\n",
    "    \"This is the result of `print(df.head())`:\\n\"\n",
    "    \"{df_str}\\n\\n\"\n",
    "    \"Follow these instructions:\\n\"\n",
    "    \"{instruction_str}\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Expression:\"\n",
    ")\n",
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Pandas Instructions (optional):\\n{pandas_instructions}\\n\\n\"\n",
    "    \"Pandas Output: {pandas_output}\\n\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "\n",
    "pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(\n",
    "    instruction_str=instruction_str, df_str=df.head(5)\n",
    ")\n",
    "pandas_output_parser = PandasInstructionParser(df)\n",
    "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188e14b-4e23-4804-8482-db0137909617",
   "metadata": {},
   "source": [
    "Looks like this: input query_str -> pandas_prompt -> llm1 -> pandas_output_parser -> response_synthesis_prompt -> llm2\n",
    "\n",
    "Additional connections to response_synthesis_prompt: llm1 -> pandas_instructions, and pandas_output_parser -> pandas_output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c1b5d1b-3585-4cb6-9e9d-42902dc783d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\": InputComponent(),\n",
    "        \"pandas_prompt\": pandas_prompt,\n",
    "        \"llm1\": llm,\n",
    "        \"pandas_output_parser\": pandas_output_parser,\n",
    "        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "        \"llm2\": llm,\n",
    "    },\n",
    "    verbose=True,\n",
    ")\n",
    "qp.add_chain([\"input\", \"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "qp.add_links(\n",
    "    [\n",
    "        Link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\"),\n",
    "        Link(\n",
    "            \"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instructions\"\n",
    "        ),\n",
    "        Link(\n",
    "            \"pandas_output_parser\",\n",
    "            \"response_synthesis_prompt\",\n",
    "            dest_key=\"pandas_output\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# add link from response synthesis prompt to llm2\n",
    "qp.add_link(\"response_synthesis_prompt\", \"llm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93c85915-252a-47fd-8063-fe78d2815ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_tokenize_internal: Added a BOS token to the prompt as specified by the model but the prompt also starts with a BOS token. So now the final prompt starts with 2 BOS tokens. Are you sure this is what you want?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: What are all the IssueTitle raised in the audit table?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: What are all the IssueTitle raised in the audit table?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "prompt: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "  ProjectCode                                       ProjectTitle  \\\n",
      "0   ...\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10763.66 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    11 runs   (    0.16 ms per token,  6406.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23834.60 ms /  1076 tokens (   22.15 ms per token,    45.14 tokens per second)\n",
      "llama_print_timings:        eval time =    8686.61 ms /    10 runs   (  868.66 ms per token,     1.15 tokens per second)\n",
      "llama_print_timings:       total time =   32554.36 ms /  1086 tokens\n",
      "llama_tokenize_internal: Added a BOS token to the prompt as specified by the model but the prompt also starts with a BOS token. So now the final prompt starts with 2 BOS tokens. Are you sure this is what you want?\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input:  df['IssueTitle'].tolist()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: What are all the IssueTitle raised in the audit table?\n",
      "pandas_instructions:  df['IssueTitle'].tolist()\n",
      "pandas_output: ['Customer segments not covered by loyalty programs ', 'Customer segments not covered by loyalty programs ', 'Enterprise customers not provided with self service loyalty redemption option', 'Enterpris...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "prompt: Given an input question, synthesize a response from the query results.\n",
      "Query: What are all the IssueTitle raised in the audit table?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      " df['IssueTitle'].tolist()\n",
      "\n",
      "Pandas...\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   10763.66 ms\n",
      "llama_print_timings:      sample time =      23.12 ms /   201 runs   (    0.12 ms per token,  8691.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3519.53 ms /   171 tokens (   20.58 ms per token,    48.59 tokens per second)\n",
      "llama_print_timings:        eval time =   49630.55 ms /   200 runs   (  248.15 ms per token,     4.03 tokens per second)\n",
      "llama_print_timings:       total time =   53459.08 ms /   371 tokens\n"
     ]
    }
   ],
   "source": [
    "response = qp.run(\n",
    "    query_str=\"What are all the IssueTitle raised in the audit table?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e81197e-0bf8-4758-9b10-ad8b0a3ec9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_tokenize_internal: Added a BOS token to the prompt as specified by the model but the prompt also starts with a BOS token. So now the final prompt starts with 2 BOS tokens. Are you sure this is what you want?\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10763.66 ms\n",
      "llama_print_timings:      sample time =       9.75 ms /   109 runs   (    0.09 ms per token, 11176.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3687.24 ms /    10 tokens (  368.72 ms per token,     2.71 tokens per second)\n",
      "llama_print_timings:        eval time =    6235.22 ms /   108 runs   (   57.73 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:       total time =    9998.35 ms /   118 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Gaps in loyalty program coverage for various customer segments\n",
      "\n",
      "2. Lack of self-service options for enterprise customers within loyalty programs\n",
      "\n",
      "3. Loyalty points expiration issue for churned customers\n",
      "\n",
      "4. Low enrollment rates for new customers on the bonga loyalty program\n",
      "\n",
      "5. Payment issues related to license fees for a system under development\n",
      "\n",
      "6. Reconciliation variances in merchandised redemption payments\n"
     ]
    }
   ],
   "source": [
    "#Issue summary\n",
    "\n",
    "print(str(llm.complete(f'can you share a list of only critical issues for higher level leadership from {str(response)}. \\\n",
    "Check if issues can be merged and merge them if they will refer to largely similar issue at a high level. \\\n",
    "Do not share any other explanation text or notes or anything else, only a list of the issues/merged issues and everything should be numbered, if its not numbered drop it')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f839d91-198e-4e8e-b037-02cab2ede0f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_tokenize_internal: Added a BOS token to the prompt as specified by the model but the prompt also starts with a BOS token. So now the final prompt starts with 2 BOS tokens. Are you sure this is what you want?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: What are all the RecommendationTitle in the audit table?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: What are all the RecommendationTitle in the audit table?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "prompt: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "  ProjectCode                                       ProjectTitle  \\\n",
      "0   ...\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10763.66 ms\n",
      "llama_print_timings:      sample time =       1.64 ms /    16 runs   (    0.10 ms per token,  9779.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16094.84 ms /  1078 tokens (   14.93 ms per token,    66.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1259.42 ms /    15 runs   (   83.96 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =   17377.65 ms /  1093 tokens\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/envs/pd_llm/lib/python3.9/site-packages/llama_index/query_engine/pandas/output_parser.py\", line 54, in default_output_processor\n",
      "    output_str = str(safe_eval(module_end_str, {\"np\": np}, local_vars))\n",
      "  File \"/opt/homebrew/anaconda3/envs/pd_llm/lib/python3.9/site-packages/llama_index/exec_utils.py\", line 140, in safe_eval\n",
      "    return eval(__source, _get_restricted_globals(__globals), __locals)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "NameError: name 'p' is not defined\n",
      "llama_tokenize_internal: Added a BOS token to the prompt as specified by the model but the prompt also starts with a BOS token. So now the final prompt starts with 2 BOS tokens. Are you sure this is what you want?\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input:  ```python\n",
      "df['RecommendationTitle'].unique()\n",
      "```\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: What are all the RecommendationTitle in the audit table?\n",
      "pandas_instructions:  ```python\n",
      "df['RecommendationTitle'].unique()\n",
      "```\n",
      "pandas_output: There was an error running the output as Python code. Error message: name 'p' is not defined\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "prompt: Given an input question, synthesize a response from the query results.\n",
      "Query: What are all the RecommendationTitle in the audit table?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      " ```python\n",
      "df['RecommendationTit...\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   10763.66 ms\n",
      "llama_print_timings:      sample time =      17.07 ms /   172 runs   (    0.10 ms per token, 10077.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1741.43 ms /    94 tokens (   18.53 ms per token,    53.98 tokens per second)\n",
      "llama_print_timings:        eval time =   13137.15 ms /   171 runs   (   76.83 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:       total time =   15032.88 ms /   265 tokens\n"
     ]
    }
   ],
   "source": [
    "response_recom = qp.run(\n",
    "    query_str=\"What are all the RecommendationTitle in the audit table?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444fae9c-281b-4845-a5b6-009929dff3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(str(llm.complete(f'can you share a list of only critical recommendations for higher level leadership from {str(response_recom)}. \\\n",
    "Check if recommendations can be merged and merge them if they will refer to largely similar recommendations at a high level. \\\n",
    "Do not share any other explanation text or notes or anything else, only a list of the issues/merged recommendations and everything should be numbered, if its not numbered drop it')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb7f89ec-84a3-42cd-9fa3-2ebca7d1a5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProjectCode', 'ProjectTitle', 'ProjectScore', 'AuditPlanTitle',\n",
       "       'ProjectQuarter', 'Division', 'ProjectSource', 'ProjectPhase',\n",
       "       'ProjectScheduledStartDate', 'ProjectScheduledEndDate', 'IssueTitle',\n",
       "       'RiskRating', 'IssueReleased', 'IssueReleaseDate', 'IssueState',\n",
       "       'RecommendationTitle', 'ManagementAction', 'DueDate', 'ReviewDueDate',\n",
       "       'RecommendationDivision', 'RecommendationState', 'TrackingStatus',\n",
       "       'LastStatusUpdate', 'LastStatusUpdateUser', 'LastStatusUpdateDate',\n",
       "       'OverdueDescription', 'OverdueStatus', 'OverdueDays', 'Auditor',\n",
       "       'IssueOwner', 'SeniorManager', 'HOD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa918c8b-6c5c-4ebf-9774-e2448d7c1c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Develop and implement loyalty program for home...\n",
       "1    Develop the enterprise loyalty program to defi...\n",
       "2    Implement the customer portal for initiation o...\n",
       "3    Ensure expiry of loyalty value for churned cus...\n",
       "4    Re-design the kindergarten message and program...\n",
       "5    Track and ensure delivery of the solution with...\n",
       "6    Re-design a daily bonga everywhere redemption ...\n",
       "Name: RecommendationTitle, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RecommendationTitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c577ac-6aee-4f42-9ba8-cb324b623c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pd_llm",
   "language": "python",
   "name": "pd_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
